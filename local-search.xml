<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Building FinTech Microservices for Data Analytics and Automated Machine Learning</title>
    <link href="/2024/09/10/automl/"/>
    <url>/2024/09/10/automl/</url>
    
    <content type="html"><![CDATA[<p><strong>Overview</strong><br>In the project, our team created four types of microservices for data collection, pre-processing, visualisation and modelling. These microservices are flexible and can be utilised to build data pipelines for different applications such as stock pricing prediction and weather forecasting. According to the client’s requirement, the microservices are just Python functions.</p><img src="/2024/09/10/automl/Overview.png" class title="Overview"><p><strong>Project Goals</strong></p><ol><li>All microservices must be developed in Python, reusable and well-documented.</li><li>All services must be executed by a common user Interface (UI) using the same workflow.</li><li>Build multiple microservices and combine microservices into a meaningful application (data pipeline: execute microservices in series). At least two data pipelines should be implemented. At least one microservice can be used by more than one data pipeline.</li><li>At least one data pipeline is related to AutoML applications.</li><li>Combine at least two different but related datasets in one data pipeline.</li><li>The microservices should be flexible enough to handle different inputs or generate different results by changing the parameters.<br><strong>System Architecture</strong><img src="/2024/09/10/automl/System_Architecture.png" class title="System Architecture"><strong>System Functionalities</strong><br><strong>Collection</strong></li><li>Data Retrieval from API<br>The microservice allows users to fetch data from external Yahoo Finance API. Users can<br>specify the API parameters, like ticker, start date and end date to retrieve the required data.<br>The microservice employs secure and efficient communication protocols to ensure the<br>confidentiality and integrity of the data during the retrieval process.</li><li>User upload dataset<br>To make a finance related model (e.g stock price prediction) usually requires years of data.<br>Fetching data from API every time could be time consuming. Hence, the collection<br>microservice also allows users to upload their own dataset for further processing.</li><li>Saving to Load Storage<br>Upon successful retrieval or upload, the data is securely stored in microservice local storage.<br>This ensures the availability and durability of the data for further processing.</li><li>Data Transformation into Pandas DataFrame<br>The retrieved data is transformed into a Pandas DataFrame, a powerful and widely used<br>data manipulation tool in Python. The transformation process is optimised for efficiency to<br>handle large datasets.</li><li>Local Copy for User Download<br>To enhance user experience, the microservice allows users to download a local copy of the<br>collected data. Users can choose the desired format (e.g., CSV, ADAGE) for the downloaded<br>file. The microservice ensures data integrity during the download process and provides<br>users with prompt feedback on the status of their download requests.</li></ol><p><strong>Pre-processing</strong></p><ol><li>Data Cleaning<br>The preprocessing microservice in our AutoML platform encompasses a broad range of<br>functionalities, specifically designed to tackle complex data quality issues. Within the data<br>cleaning section, two key features are prominently available: ‘Remove Null Values’ and<br>‘Remove Duplicates’. We have meticulously developed custom functions for these features,<br>aptly named remove_null and remove_duplicate, respectively. Users can effortlessly remove<br>null values and duplicates from their dataset with just a single click on the respective<br>buttons.</li></ol><img src="/2024/09/10/automl/Data_Cleaning_Buttons.png" class title="Data Cleaning Buttons"><ol start="2"><li>Data Filtering<br>The Data Filtering section of the platform empowers users to refine their dataset effectively<br>by offering two significant functionalities: filtering by date range and dropping columns. Users<br>can specify a start and end date to filter their data within a certain period, and they also have<br>the option to exclude specific data dimensions by dropping columns. This flexibility allows<br>users to concentrate on the data that is most relevant and crucial for their subsequent<br>analysis. To facilitate these features, we have developed custom functions named date_filter<br>and drop_column, specifically tailored to execute these tasks efficiently.</li></ol><ol start="3"><li>Data Transformation<br>The data transformation microservices focus on preparing and manipulating data for<br>analysis. This involves unpacking, aggregating, and filling missing data in time series.<br>3.1 Unpacking Dictionary Columns<br>The function is designed to expand dictionary-like data within a DataFrame column into<br>separate columns. This is crucial for extracting nested information, such as sentiments, from<br>a single column.<br>3.2 Average Column Calculation<br>For example, if the column is sentiment, then the function computes the average sentiment<br>for each date. It groups data by date and calculates the mean of each sentiment column,<br>which is essential for time-series analysis. In this case the daily sentiment averages can<br>indicate market trends.<br>3.3 Data Filling Strategies<br>The functions address missing data in time series. Forward filling replicates the last known<br>data point, and zero filling inserts zeros. These methods are vital for maintaining the<br>continuity of time series data.</li></ol><p><strong>Visualisation</strong></p><ol><li>Generation page<br>Data generation is an essential step before visualisation. Once the data has been loaded<br>and verified, they can be passed into the visualisation functions we create (will be discussed<br>later), producing intuitive candle plots and line plots. Our visualisation tools, such as the time<br>slider below the chart, further enhance the user experience, allowing users to focus on a<br>specific time frame to explore detailed changes in stock prices.<br>When integrating the “data generation” section of the report, we emphasise the technical<br>details of data preprocessing and loading, as well as how to turn this data into a visual table.<br>1.1 Data Collection<br>In order to improve the effectiveness and accuracy of our visualisation module, we have<br>introduced data generation steps in the AutoML platform. This step focuses on the<br>acquisition and pre-processing of raw stock data, through to the final loading and display.<br>The screenshot shown below is the data generation page on our platform, which shows the<br>stock data in tabular form.</li></ol><img src="/2024/09/10/automl/Data_Generation_Page.png" class title="Data_Generation_Page"><p>Our system is designed with reusability in mind. For example, the call to the render_template<br>function gives us the flexibility to use the same data table component for different data sets<br>and pages. This modular approach makes the platform easy to maintain and extend.<br>On the back end, the &#x2F;generation routing code handles the entire process from file deletion,<br>data reading, and template rendering. Error handling mechanisms are included in this<br>process to ensure robustness, for example, if the preprocessed file does not exist, we try to<br>delete it to avoid redundancy and potential data inconsistencies.</p><ol start="2"><li>Visualisation Page<br>In the modern FinTech space, data visualisation plays an important role in helping users<br>understand complex data. The purpose of this report is to detail the visualisation module in<br>our project, which focuses on converting stock market data into intuitive charts and graphs to<br>help users better understand the dynamics of the stock market.<br>Combined with data filtering and transformation steps, our visual microservices generate<br>graphs that reflect the most relevant data insights.</li></ol><img src="/2024/09/10/automl/Visualisation_Page.png" class title="Visualisation_Page"><p>We use the Plotly graph library to create intuitive charts based on filtered and transformed<br>data sets, such as candle charts and line charts, which visually show fluctuations and trends<br>in stock prices and market sentiment.</p><p><strong>Modelling</strong></p><ol><li>AutoML<br>The model microservices are designed to automate the process of forecasting time series<br>data using AutoGluon (Shchur et al., 2023). It primarily focuses on predicting future values<br>based on historical data, which is crucial in various domains like stock market analysis,<br>weather forecasting.</li><li>Data Preparation for AutoML<br>Function divides the dataset into training and testing sets based on a specified date column<br>and test rate. This is crucial for evaluating the model’s performance on unseen data.<br>Function standardises the column names, ensuring consistency and compatibility with the<br>AutoGluon library.</li><li>Model Training<br>Function utilises the TimeSeriesPredictor from AutoGluon, which trains a model to predict<br>future values of a specified target column for a given number of days ahead. This can be<br>used for training the model with training dataset, as well as refitting the model with full<br>dataset.</li><li>Logger<br>Helper class and functions for monitoring the progress of AutoML training, which count the<br>number of logs and smooth the percentage of progress bar.</li></ol><img src="/2024/09/10/automl/Training_Page.png" class title="Training_Page"><ol start="5"><li>Model Evaluation<br>Function generates leaderboards using the trained models on both the test and full datasets.<br>This provides insights into the model’s performance and helps in selecting the best model for<br>prediction.</li><li>Forecasting<br>Function makes predictions on new data, outputting a dataframe for future trends.</li></ol><img src="/2024/09/10/automl/Results_Page.png" class title="Results_Page"><p><strong>User Interface and User experience</strong><br>AutoML is designed by considering responsive, reusable and meaningful screens and<br>components. All the components and screens are responsive to desktop, tablet and mobile<br>devices.</p><ol><li>Responsiveness<br>The user interface of AutoML web app accommodates major platforms which can run web<br>apps including Desktop, Tablet and mobile below are the screenshots of the same<br>Here you can see that the buttons and the content changes its orientation and adapts to the<br>respective view.<br>The respective row layout in the desktop view changes into column</li></ol><img src="/2024/09/10/automl/Desktop_View.png" class title="Desktop_View"><img src="/2024/09/10/automl/Phone_and_Tablet_View.png" class title="Phone_and_Tablet_View"><ol start="2"><li>Common Components &#x2F; Adaptive Components<br>AutoML app heavily leverages Common and adaptive components at wherever necessary<br>to maintain consistency and code reuse for the code bases<br>Consistency: By employing common components, AutoML maintains a consistent look and<br>feel. This uniformity helps in maintaining the same user experience throughout the app while<br>ensuring that the user interface is coherent and intuitive. Moreover standardising practices<br>and conventions across different parts of the application.<br>Leveraging Code Reuse: The use of adaptive and common components promotes the<br>reuse of code leading towards more efficient development process, quicker turnaround times<br>for new features, and fewer errors, as well-tested components are reused rather than<br>creating new components for example the tables and buttons are using a shared under the<br>hoods the table which is displayed in 5 screens hence is the same component and the<br>buttons through the app<br>Easier to Maintain and Upgrade: Since our web app relies on reusable components,<br>maintaining and updating the application becomes simpler. Modifications or improvements<br>made to a common component automatically propagate to all parts of the application which<br>are using the same components resulting in reduction of time and effort needed to<br>implement changes across the application.<br>Adaptable and scalable: Adaptive components allow the application to be more flexible and<br>scalable. They can adjust to different contexts and requirements, making the application more robust and versatile. Like we have adapted the table component in all the five screens<br>and we can also scale the table to use either a data frame or a csv.</li></ol><img src="/2024/09/10/automl/Phone_and_Tablet_View_of_Progress_Bar.png" class title="Phone_and_Tablet_View_of_Progress_Bar"><ol start="3"><li>Preprocessing<br>3.1 Preprocessing Page Overview<br>The AutoML platform features a dedicated preprocessing page that enables users to easily<br>clean, filter, sort, and transform data for further analysis and modelling. The platform<br>seamlessly integrates front-end interactivity with robust back-end processing. The<br>user-friendly web interface comprises three clearly defined sections: Data Cleaning, Data<br>Filtering, and Data Preview, which show users the immediate impact of their preprocessing<br>actions.</li></ol><img src="/2024/09/10/automl/Preprocessing_Page_Overview.png" class title="Preprocessing_Page_Overview"><p>3.2 Data Preview<br>The Data Preview section displays the data table, where users can view the generated data<br>from the previous generation page and see the results after applying preprocessing features.<br>This section shows the immediate effect of their preprocessing actions, granting users<br>control over their data. Additionally, users have the option to select the number of entries<br>they wish to display and can search for keywords within the dataset using the provided<br>search box.</p><img src="/2024/09/10/automl/Data_Preview_Overview.png" class title="Data_Preview_Overview"><p>3.3 Data Sorting<br>To enhance user experience and interactivity in the UI, each column in the displayed table is<br>accompanied by arrows for sorting. An upward arrow next to a column name enables the<br>user to sort that column in ascending order, while a downward arrow facilitates sorting in<br>descending order. This feature allows users to quickly and efficiently organise their data in<br>the desired order, simply by clicking on the respective arrow beside each column header.</p><img src="/2024/09/10/automl/Data_Sorting_Arrows.png" class title="Data_Sorting_Arrows"><p>3.4 Preprocessing Results<br>The preprocessed data is ultimately displayed in a table in the Data Preview section, ready<br>for further visualisation, analysis, and modelling purposes. Users also have the option to<br>download the preprocessed data by clicking on the button labelled ‘Download Preprocessed<br>Data’.</p><img src="/2024/09/10/automl/Download_Prepr_cessed_Data_Button.png" class title="Download_Prepr_cessed_Data_Button"><ol start="4"><li>Visualisation<br>Users can choose to generate an OHLC chart or a line chart table by clicking a button on the<br>interface.</li></ol><img src="/2024/09/10/automl/OHLC_Chart.png" class title="OHLC_Chart"><p>4.1 OHLC chart<br>In the OHLC chart, you see the picture below</p><img src="/2024/09/10/automl/Graph_1.png" class title="Graph_1"><p>Each candlestick represents a day’s stock price, and when you hover over a particular day, it<br>will show the day’s date and the average stock price for that day.</p><img src="/2024/09/10/automl/Graph_2.png" class title="Graph_2"><p>On the top right of the picture you can see a row of function buttons. If you want to save the<br>image locally you can click on the camera button and the image will be saved in png format<br>on your computer, the pan button allows you to select the portion of the stock price date you<br>want to select then zoom in, the box select and lasso select allow you to select any area of<br>the image you want, there is also zoom in and zoom out functionality and the ability to reset<br>the entire image.</p><img src="/2024/09/10/automl/Function_Buttons.png" class title="Function_Buttons"><p>The sliders underneath allow you to shorten or zoom in on the time period you want to<br>observe. Of course, if you find the price changes of a certain period is interesting and you<br>want to analyse it quickly by selecting this period of the chart, you just need to select the part<br>of the chart you are interested in with your mouse and it will be zoomed in automatically on<br>the period you have selected, if you want to go back to the original chart, you just need to<br>double-click on the mouse and you will be able to return to the original chart.</p><img src="/2024/09/10/automl/Graph_3.png" class title="Graph_3"><p>4.2 Line chart<br>Similarly, all of the above features are also available on the line chart if you choose to use it,<br>which gives you a more visual picture of the trend of the selected stock over the time period.<br>Each type of chart is designed for specific user needs, whether it is to analyse in depth the<br>specific performance of a single stock or to observe the overall trend of the stock price.</p><img src="/2024/09/10/automl/Line_Chart.png" class title="Line_Chart"><p>Our visualisation module plays a key role in making stock market data analysis more intuitive<br>and user-friendly. It is not only suitable for professional investors, but also provides value to<br>ordinary stock market enthusiasts. In the future, we plan to continue optimising the module<br>by introducing more interactive features and chart types to meet a wider range of user<br>needs.</p><p><strong>Implementation Challenges</strong><br>High level framework vs Customised UI<br>In the project proposal, we planned to use Streamlit for front-end UI implementation.<br>Streamlit is an innovative and user-friendly Python library that simplifies the process of<br>creating interactive web applications for data science and machine learning. With Streamlit,<br>developers can transform data scripts into shareable web apps with just a few lines of code,<br>eliminating the need for extensive web development expertise.<br>However, as a high level UI framework, the simplicity comes with a cost being very difficult to<br>customise for use, it does not provide enough flexibility. For instance, in our AutoML<br>platform, users use our microservices to form a pipeline. Streamlit does not have a pipeline<br>like navigation bar. It only allows users to navigate using sidebars. It is a viable<br>implementation for users to navigate, but it is not a user friendly solution.<br>Hence, we created a new battle plan and decided to switch to Flask for the front-end. Flask<br>allows us to write customised HTML UI templates with JQuery. We made the decision after<br>the first demonstration, therefore, during the second sprint, we faced a challenge of<br>refactoring sprint one UI to Flask and finishing sprint two on time. To tackle the challenge, we<br>fully utilised the flexible week to have coding sessions to increase our work efficiency and<br>quality. Coding session helped us to quickly refactored the code to Flask and left us enough<br>time for sprint two development.<br>Team Programming Version Control<br>Team based projects are profoundly different from individual projects. In an individual<br>project, one person could code any part of the project in any way and any time preferred.<br>However, team based coding is more complicated. It requires all team members to adhere to<br>the correct version control method.<br>For most team members, it was the first time using JIRA for project management and<br>working on a real-life-like project. Members had no ideas how to utilise Git properly to control<br>code versions. For instance, one member needs to create a branch to make modifications or<br>develop new features, then create a Pull Request to merge changes into the main branch.<br>The correct workflow ensures new code has good quality and can be safely merged into the<br>main branch. At the beginning of the project, without using the correct Git workflow, the<br>coding progress was strongly influenced by the problem. Team members had to share and<br>check progress using team chat.<br>To resolve the problem, we hosted a meeting to familiarise ourselves with Git workflow. We<br>ensured everyone can use JIRA for user story and branch creation, know how to create Pull<br>Requests and approve then merge other’s Pull Requests. After the meeting, we successfully<br>resolved this challenge, we could maximise our efficiency to increase the project quality.</p><p><strong>Third Party Libraries</strong><br><em><strong>Flask</strong></em><br>Pallets. (n.d.). Pallets&#x2F;flask: The Python Micro Framework for building web<br>applications. GitHub. <a href="https://github.com/pallets/flask/">https://github.com/pallets/flask/</a><br>We used Flask for UI implementation. One standout feature about Flask is that it allows us to<br>create UI templates. In our AutoML platform, we need to use tables to visualise data to<br>users. With the help of UI components, we could implement one table template and reuse it<br>in different pages. This modular design not only enhances code readability but also<br>simplifies updates and modifications.<br>In our project, we used Flask for routing, each microservice has one endpoint, calling the<br>endpoint brings users to corresponding pages. We created two types of UI templates. The<br>first type is components, which are reusable minimum elements for User Interface. The<br>second type is pages, which contain components to form endpoint corresponding pages.<br><em><strong>Pandas</strong></em><br>Pandas-Dev. (n.d.). Pandas-dev&#x2F;Pandas: Flexible and powerful data analysis &#x2F;<br>manipulation library for python, providing labelled data structures similar to R<br>data.frame objects, statistical functions, and much more. GitHub.<br><a href="https://github.com/pandas-dev/pandas">https://github.com/pandas-dev/pandas</a><br>Pandas is an open-source Python library which is extensively used for data manipulation<br>and analysis. It provides data structures and functions to efficiently handle and analyse<br>structured data. We have utilised Pandas in our AutoML platform for various microservices<br>including collection, model, preprocessing, and even within our Flask app code.<br>Pandas plays a crucial role in our AutoML platform, due to its efficiency, adaptability, and<br>strong capabilities in handling data. Its features align seamlessly with the requirements of<br>data analysis and automated machine learning, making it an essential tool in our system.<br><em><strong>Plotly</strong></em><br>Plotly. (n.d.). Plotly&#x2F;plotly.py: The Interactive Graphing Library for Python this project<br>now includes Plotly Express!. GitHub. <a href="https://github.com/plotly/plotly.py">https://github.com/plotly/plotly.py</a><br>Plotly is an open source graphics library for creating interactive charts and data<br>visualisations. It supports several programming languages, including Python, R, Julia, and<br>JavaScript. Plotly makes it easy for users to build complex graphs, increasing the<br>intuitiveness of data analysis and user interaction.<br><em><strong>AutoGluon</strong></em><br>Shchur, O., Turkmen, C., Erickson, N., Shen, H., Shirkov, A., Hu, T., &amp; Wang, Y. (2023,<br>August 10). Autogluon-timeseries: Automl for probabilistic time series forecasting.<br>arXiv.org. <a href="https://arxiv.org/abs/2308.05566">https://arxiv.org/abs/2308.05566</a><br>AutoGluon is an AutoML Library for Image, Text, Time Series, and Tabular Data. In this<br>project we used the time series forecasting functionality.<br><em><strong>Yfinance</strong></em><br>yfinance: Download market data from Yahoo! Finance’s API. GitHub.<br><a href="https://github.com/ranaroussi/yfinance">https://github.com/ranaroussi/yfinance</a><br>Yfinance is an open-source publicly available API, it allows us to fetch financial data to<br>conduct research.<br>The API is easy to use, with a ticker, a start date and an end date, it allows users to fetch<br>stock data. The API is free to use and reliable.<br><strong>User Manual</strong><br><em><strong>Installation</strong></em></p><ol><li>Prerequisite: Before beginning the installation, ensure Python 3.10 is installed on your<br>system. This is an essential step for the proper functioning of the application.</li><li>Clone the Repository: The first step involves cloning the repository to your local machine.<br>This action copies all the necessary files you need to start setting up the application.</li><li>Navigation to Project Directory: Once the repository is cloned, open a terminal or<br>command prompt. Navigate to the project directory by executing the command:<br>cd app<br>This will change your current directory to the project folder.</li><li>Installing Required Packages: In the project directory, you need to install several<br>dependencies. This is done using pip, Python’s package installer, with the following<br>command:<br>pip install -r requirements.txt<br>This command reads the ‘requirements.txt’ file and installs all the packages listed there.</li><li>Install AutoGluon: AutoGluon is an essential component of our application. Follow the<br>installation guide available at AutoGluon’s official installation page<br>(<a href="https://auto.gluon.ai/stable/install.html">https://auto.gluon.ai/stable/install.html</a>) to install this package.<br><strong>Running the Application</strong></li><li>Activating the Python Environment: Before running the application, ensure the Python<br>environment where you installed the dependencies is activated.</li><li>Starting the Application: To start the application, run the Flask app with debugging mode<br>enabled. This can be done by executing the following command in the terminal:<br>flask –app app.py –debug run<br>This command starts the Flask server with the application, allowing you to access it through<br>a web browser.<br><strong>Understanding the Project Structure</strong><br>The project organised for easy navigation and modification:<br>● app Directory: Contains the main application and modules for various microservices.<br>○ helpers: Includes utility scripts and helper functions that assist in various<br>tasks.<br>○ microservices : Contains services for data collection, modelling,<br>preprocessing, results, and visualisation.<br>○ ui: Hosts user interface components and HTML pages for different<br>functionalities.<br>● app.py: This is the main Python file used to run the Flask application.<br>● setup&#x2F;Requirements.txt: Lists all the dependencies required for the project.<br>● README.md: Contains detailed setup instructions and additional information about<br>the project.<br>Usage</li><li>After landing on the welcome page, click on the ‘Get Started’ button.</li></ol><img src="/2024/09/10/automl/Welcome_Page.png" class title="Welcome_Page"><ol start="2"><li>The user will be directed to the Collection page of the AutoML platform. The user can<br>choose to fetch data from an API or upload a local dataset by clicking on the respective<br>buttons. To fetch data from the API, use ‘AAPL’ as the ticker, input preferred start and end<br>dates, and use ‘demo’ as the API Token.</li></ol><img src="/2024/09/10/automl/Collection_Page.png" class title="Collection_Page"><ol start="3"><li>The fetched data is displayed on the Generation page. The user can choose to download<br>the data or download ADAGE by clicking on the respective buttons</li></ol><img src="/2024/09/10/automl/Data_Generation_Page.png" class title="Data_Generation_Page"><ol start="4"><li>On the Preprocessing page, the user can clean the data by removing null values and<br>duplicates using the ‘Remove Null Values’ and ‘Remove Duplicates’ buttons respectively.<br>Furthermore, the data can be filtered based on a specified date range and unnecessary<br>columns can be excluded using the provided data filtering features.<br>The preprocessed data is displayed in a table format in the data preview section. The data<br>can be sorted in either ascending or descending order using the arrows provided beside the<br>column names in the table. The user can also choose to download the preprocessed data by<br>clicking the ‘Download Preprocessed Data’ button.</li></ol><img src="/2024/09/10/automl/Preprocessing_Page_Overview.png" class title="Preprocessing_Page_Overview"><img src="/2024/09/10/automl/Data_Preview_Overview.png" class title="Data_Preview_Overview"><img src="/2024/09/10/automl/Download_Prepr_cessed_Data_Button.png" class title="Download_Prepr_cessed_Data_Button"><ol start="5"><li>After the user is satisfied with pre-processed data, the user can navigate to the<br>visualisation page. Two plots about the dataset will be generated. The first one is the OHLC<br>chart, which shows the user the key stock price of a day (e.g. low, high). The second one is<br>an average line chart, which shows the user the average stock price for each day.</li></ol><img src="/2024/09/10/automl/Average_Line_Chart.png" class title="Average_Line_Chart"><ol start="6"><li>After the dataset is prepared, the user can navigate to the modelling page. In the<br>modelling page, the user will have a dropdown list of each column in the dataset. The user<br>can choose one column they want to predict and number of days to predict. Finally, with one click on the start button, the AutoML will handle the rest (e.g. train Time Series Model to<br>predict).</li></ol><img src="/2024/09/10/automl/Modelling_page.png" class title="Modelling_page"><p>While the models are being trained, the user will see a progress bar to know when the<br>training will be finished and be able to see results.<br>7. Ultimately, when the training is finished, the user can navigate to the result page and view<br>detailed results from each model. Models will be sorted in performance order from the most<br>accurate to the least accurate.<br>Moreover, the user can also view predicted results from each model by choosing the model<br>from the dropdown bar. Then click the ‘start predicting’ button to show all predictions.</p><img src="/2024/09/10/automl/Results_Page1.png" class title="Results_Page1">]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>Data Analytics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>automl</tag>
      
      <tag>Python</tag>
      
      <tag>microservices</tag>
      
      <tag>data pipeline</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How I Built the AirBrB with ReactJS</title>
    <link href="/2024/09/06/airbrb/"/>
    <url>/2024/09/06/airbrb/</url>
    
    <content type="html"><![CDATA[<p><strong>Introduction</strong><br>AirBrB is a property rental platform inspired by Airbnb, allowing users to list, search, and book properties. In this project, I focused on building the frontend using ReactJS. The goal was to create a responsive single-page application (SPA) that interacts with a backend API, offering features like user authentication, property listing management, booking capabilities, and advanced search filters.</p><p><strong>Project Overview</strong><br><strong>1. User Authentication</strong><br>The platform supports user authentication, allowing users to register, log in, and log out. Once logged in, users can access additional features like creating and managing listings, as well as booking properties.</p><p>Login Page: Allows users to input their email and password.<br>Registration Page: Users provide their name, email, password, and confirm their password.<br>Logout Functionality: The logout button is available on all pages when the user is logged in.</p><img src="/2024/09/06/airbrb/login.png" class title="login"><img src="/2024/09/06/airbrb/logout.png" class title="logout"><img src="/2024/09/06/airbrb/loginc.png" class title="login"><img src="/2024/09/06/airbrb/regis.png" class title="regist"><p><strong>2. Creating &amp; Managing Listings</strong><br>Once logged in, users (hosts) can create property listings. They can manage their listings through a dashboard, where they can edit or delete existing properties. Listings become visible to other users once published.</p><p>Hosted Listings Screen: Displays all listings created by the user, showing details like property type, number of beds, price, etc.<br>Create Listing: Allows users to provide details such as title, address, price, and amenities.<br>Edit Listing: Users can update their existing listings.<br>Delete Listing: Users can remove listings they no longer want to display.</p><img src="/2024/09/06/airbrb/publish.png" class title="publish"><img src="/2024/09/06/airbrb/inv.png" class title="inv"><p><strong>3. Viewing &amp; Searching Listings</strong><br>All users, whether logged in or not, can browse property listings. The platform provides filters to help narrow down results based on user preferences, such as price, number of bedrooms, and availability.</p><p>Listings Screen: Displays all available (published) listings, showing the title, price, images, and reviews.<br>Search Filters: Users can filter listings based on title, city, price range, number of bedrooms, and availability dates.<br>Sorting: Users can sort listings by review ratings, making it easier to find highly-rated properties.</p><img src="/2024/09/06/airbrb/avhouse.png" class title="avhouse"><img src="/2024/09/06/airbrb/inv.png" class title="inv"><p><strong>4. Booking a Listing</strong><br>Logged-in users can select a property and book it. Users choose a date range for their stay and confirm the booking. The booking is then processed by the backend.</p><p>Booking Functionality: Users select dates and submit a booking request.<br>View Booking Status: Users can check the status of their bookings (pending, accepted, or denied).</p><img src="/2024/09/06/airbrb/reserve.png" class title="reserve"><img src="/2024/09/06/airbrb/re.png" class title="reserve"><p><strong>5. Reviews &amp; Ratings</strong><br>Users can leave reviews for properties they have booked. This helps future users get a better sense of the property’s quality and the host’s reliability.</p><p>Leave a Review: After completing a booking, users can leave a rating and a comment for the property.<br>View Reviews: Other users can see reviews left by previous guests, including ratings and feedback.</p><img src="/2024/09/06/airbrb/review.png" class title="review"><p><strong>Advanced Features</strong><br><strong>1. Star Rating Breakdown</strong><br>When hovering over the star rating, a tooltip shows the percentage of reviews in each star category. This feature is similar to rating systems seen on e-commerce platforms.</p><p><strong>2. Profit Tracking</strong><br>For property hosts, the platform provides a profit tracking graph that shows the income earned from their listings over the past month. This allows hosts to monitor their earnings.</p><p><strong>3. YouTube Thumbnails</strong><br>To make property listings more engaging, hosts can use YouTube videos as the listing thumbnail. This gives potential renters a better sense of the property with a video tour.</p><p><strong>Development Process</strong><br>During development, one of the key challenges was ensuring that the frontend communicated efficiently with the provided backend API. I used React’s useState and useEffect hooks to manage state and fetch data dynamically. React Router was employed to handle navigation between different views without refreshing the page, providing a seamless user experience.</p><p>From a UI&#x2F;UX perspective, I focused on making the platform intuitive and responsive. The design was tested on different devices and screen sizes to ensure a smooth experience for both mobile and desktop users.</p><p><strong>Conclusion</strong><br>This project provided an in-depth learning experience in ReactJS, allowing me to build a fully functional, user-friendly application. From user authentication to booking and review systems, the AirBrB frontend offers a wide range of features. The added advanced functionality, like profit tracking and star rating breakdown, further enhances the user experience. If you have any questions about this project, feel free to reach out!</p>]]></content>
    
    
    <categories>
      
      <category>frontend</category>
      
    </categories>
    
    
    <tags>
      
      <tag>html</tag>
      
      <tag>react</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2021/06/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/"/>
    <url>/2021/06/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章</p><p>Introduction<br>AirBrB is a property rental platform inspired by Airbnb, allowing users to list, search, and book properties. In this project, I focused on building the frontend using ReactJS. The goal was to create a responsive single-page application (SPA) that interacts with a backend API, offering features like user authentication, property listing management, booking capabilities, and advanced search filters.</p><p>Project Overview</p><ol><li>User Authentication<br>The platform supports user authentication, allowing users to register, log in, and log out. Once logged in, users can access additional features like creating and managing listings, as well as booking properties.</li></ol><p>Login Page: Allows users to input their email and password.<br>Registration Page: Users provide their name, email, password, and confirm their password.<br>Logout Functionality: The logout button is available on all pages when the user is logged in.</p><ol start="2"><li>Creating &amp; Managing Listings<br>Once logged in, users (hosts) can create property listings. They can manage their listings through a dashboard, where they can edit or delete existing properties. Listings become visible to other users once published.</li></ol><p>Hosted Listings Screen: Displays all listings created by the user, showing details like property type, number of beds, price, etc.<br>Create Listing: Allows users to provide details such as title, address, price, and amenities.<br>Edit Listing: Users can update their existing listings.<br>Delete Listing: Users can remove listings they no longer want to display.</p><ol start="3"><li>Viewing &amp; Searching Listings<br>All users, whether logged in or not, can browse property listings. The platform provides filters to help narrow down results based on user preferences, such as price, number of bedrooms, and availability.</li></ol><p>Listings Screen: Displays all available (published) listings, showing the title, price, images, and reviews.<br>Search Filters: Users can filter listings based on title, city, price range, number of bedrooms, and availability dates.<br>Sorting: Users can sort listings by review ratings, making it easier to find highly-rated properties.</p><ol start="4"><li>Booking a Listing<br>Logged-in users can select a property and book it. Users choose a date range for their stay and confirm the booking. The booking is then processed by the backend.</li></ol><p>Booking Functionality: Users select dates and submit a booking request.<br>View Booking Status: Users can check the status of their bookings (pending, accepted, or denied).</p><ol start="5"><li>Reviews &amp; Ratings<br>Users can leave reviews for properties they have booked. This helps future users get a better sense of the property’s quality and the host’s reliability.</li></ol><p>Leave a Review: After completing a booking, users can leave a rating and a comment for the property.<br>View Reviews: Other users can see reviews left by previous guests, including ratings and feedback.</p><p>Advanced Features</p><ol><li><p>Star Rating Breakdown<br>When hovering over the star rating, a tooltip shows the percentage of reviews in each star category. This feature is similar to rating systems seen on e-commerce platforms.</p></li><li><p>Profit Tracking<br>For property hosts, the platform provides a profit tracking graph that shows the income earned from their listings over the past month. This allows hosts to monitor their earnings.</p></li><li><p>YouTube Thumbnails<br>To make property listings more engaging, hosts can use YouTube videos as the listing thumbnail. This gives potential renters a better sense of the property with a video tour.</p></li></ol><p>Development Process<br>During development, one of the key challenges was ensuring that the frontend communicated efficiently with the provided backend API. I used React’s useState and useEffect hooks to manage state and fetch data dynamically. React Router was employed to handle navigation between different views without refreshing the page, providing a seamless user experience.</p><p>From a UI&#x2F;UX perspective, I focused on making the platform intuitive and responsive. The design was tested on different devices and screen sizes to ensure a smooth experience for both mobile and desktop users.</p><p>Conclusion<br>This project provided an in-depth learning experience in ReactJS, allowing me to build a fully functional, user-friendly application. From user authentication to booking and review systems, the AirBrB frontend offers a wide range of features. The added advanced functionality, like profit tracking and star rating breakdown, further enhances the user experience. If you have any questions about this project, feel free to reach out!</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
